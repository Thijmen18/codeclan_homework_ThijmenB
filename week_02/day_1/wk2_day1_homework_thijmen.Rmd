---
title: "R Notebook"
output: html_notebook
---

# Homework Week2_day1 Thijmen

## `Joins`
# Question 1
**Question 1**

Read in all 4 credit card transaction datasets and clean column names.

```{r}
library(tidyverse)
cardbase <- read_csv("data/CardBase.csv") %>% 
 janitor::clean_names()
cardbase

customerbase <- read_csv("data/CustomerBase.csv") %>% 
   janitor::clean_names()
customerbase

fraudbase <- read_csv("data/FraudBase.csv") %>% 
   janitor::clean_names()
fraudbase

transactionbase <- read_csv("data/TransactionBase.csv") %>% 
   janitor::clean_names()
transactionbase

# Clean column names using the lazy method: janitor::clean_names()
```

**Question 2**

Join the data containing card details and customer details by customer id, so that 
all records of card details and any matching records in customer details are kept. 
Before you run the code, think about how many rows you expect to see after joining.

```{r}
# cardbase has 500 rows
# customerbase has 5674 rows

# I expect 500 rows, a single row per card

left_join(cardbase, customerbase, by = "cust_id")
```

**Question 3**

Join the data containing fraud details with transaction details so all rows of 
both tables are kept. What does the resulting row number tell you?

```{r}
fraudbase
# has 109 rows
transactionbase
# has 10000 rows

full_join(fraudbase, transactionbase, by = "transaction_id")

# we have 10000 rows, so 109 transactions of all transactions were probably a fraud
```

**Question 4**

Join the data containing card details with transaction details so rows from the 
first which have matching ones in the second are returned, but only return rows in the first table once.
```{r}
cardbase #500 rows
transactionbase #10k rows

semi_join(cardbase, transactionbase, by = c("card_number" = "credit_card_id"))


```

## `tidyr`

**Question 5**

Read in `hat_observations` and separate `observation` into two columns, `hat_colour` and `hat_type`.

```{r}
hats <- read_csv("data/hat_observations.csv")

hats_separate <- hats %>% 
  separate(observation,
           c("hat_colour", "hat_type"),
           sep = ",")
 
hats_separate
  #success!

```

**Question 6**

Unite `day`, `month`, and `year` columns into a column called `date` using a 
suitable separator. Then find the date where the most berets were observed.

```{r}
hats_date_comb <- hats_separate %>% 
  unite(date, 
        c("day", "month", "year"),
        sep = "/"
        )
        

hats_date_comb %>% 
  filter(hat_type == "beret") %>% 
  slice_max(observation_count, n = 1)

# 9 on 18/6/2018!

```

# Extension

## Joins

**Question 1**

Can you join all 4 datasets together so that you're left with a dataset that looks like below with **109 rows** and **12 columns**?

![](images/all_joined.png)

```{r}
cardbase 
customerbase # with previous cust_id
transactionbase # with previous card_number - credit_card_id
fraudbase # with previous, overlap is transaction_id

inner_join(cardbase, customerbase, by = "cust_id") %>% 
  inner_join(transactionbase, by = c("card_number" = "credit_card_id")) %>% 
  inner_join(fraudbase, by = "transaction_id")

# success!

```

## `tidyr`

**Question 2**

Read in `exam_scores` and transform it into long format with two new columns `exam_question` and `score`. Then, using `separate` and `select`, remove superfluous information from the values in `exam_question`

```{r}
exam_score <- read_csv("data/exam_scores.csv")
exam_score

exam_score %>% 
  pivot_longer(cols = starts_with("exam_Q"),
               names_to = "exam_question",
               values_to = "score") %>% 
  separate(exam_question,
           c("prefix", "exam_question"),
           sep = "Q") %>% 
  select(id, exam_question, score)
```

